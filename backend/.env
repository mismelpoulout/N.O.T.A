# ==============================================
# üîß CONFIGURACI√ìN PRINCIPAL N.O.T.A BACKEND
# ==============================================

# --- Rutas internas ---
DATA_DIR=./backend/data
SQLITE_DB=./backend/data/medical.db
CORPUS_JSONL=./backend/data/corpus.jsonl

# ==============================================
# ü§ñ MODELO LLM (Ollama / LM Studio / OpenAI-Compatible)
# ==============================================

# Servidor LLM local (Ollama expone /v1 compatible OpenAI)
LLM_BASE_URL=http://127.0.0.1:11434/v1

# Modelo ACTIVO (exactamente el que tienes en `ollama list`)
LLM_MODEL=llama3.1:8b-instruct-q4_K_M

# Clave ‚Äúde cortes√≠a‚Äù (Ollama no la exige, pero mantenla por compatibilidad)
LLM_API_KEY=ollama

# ==============================================
# ‚öôÔ∏è PAR√ÅMETROS DE SISTEMA
# ==============================================

# Cach√© de respuestas (TTL en segundos)
CACHE_TTL_SECONDS=86400

# ==============================================
# üåç Preferencias de Ranking / B√∫squeda
# ==============================================

# Prioriza dominios confiables (separados por coma)
PREFERRED_DOMAINS=minsal.cl,intramed.net,medlineplus.gov,mayoclinic.org

# ==============================================
# üöÄ ENTORNO (usado en app.py)
# ==============================================
ENV=development
ENABLE_DOCS=true
ALLOWED_ORIGINS=*
TRUSTED_HOSTS=localhost,127.0.0.1
FORCE_HTTPS=false